{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a56306ee",
   "metadata": {
    "id": "a56306ee"
   },
   "source": [
    "# Comparative analysis for defect detection in software applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2634b314",
   "metadata": {
    "id": "2634b314"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import plotly as py\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b78c46c",
   "metadata": {
    "id": "0b78c46c"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "data = drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d17ee6a",
   "metadata": {
    "id": "0d17ee6a"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/csv_result-jm1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55259e22",
   "metadata": {
    "id": "55259e22"
   },
   "outputs": [],
   "source": [
    "data.head()\n",
    "data = data.drop(columns = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850b2e29",
   "metadata": {
    "id": "850b2e29",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a9333a",
   "metadata": {
    "id": "f1a9333a"
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e0157b",
   "metadata": {
    "id": "32e0157b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb03aa0",
   "metadata": {
    "id": "cfb03aa0"
   },
   "source": [
    "### 1. Replacing ? with Not a Number in the Miscellaneous Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0684b0f0",
   "metadata": {
    "id": "0684b0f0"
   },
   "outputs": [],
   "source": [
    "data['uniq_Op'] = data['uniq_Op'].replace('?', np.NaN)\n",
    "data['uniq_Opnd'] = data['uniq_Opnd'].replace('?', np.NaN)\n",
    "data['total_Op'] = data['total_Op'].replace('?', np.NaN)\n",
    "data['total_Opnd'] = data['total_Opnd'].replace('?', np.NaN)\n",
    "data['branchCount'] = data['branchCount'].replace('?', np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59f6df7",
   "metadata": {
    "id": "b59f6df7"
   },
   "source": [
    "### 2. Converting Object Data type to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469100f8",
   "metadata": {
    "id": "469100f8"
   },
   "outputs": [],
   "source": [
    "data['uniq_Op'] = pd.to_numeric(data['uniq_Op'])\n",
    "data['uniq_Opnd'] = pd.to_numeric(data['uniq_Opnd'])\n",
    "data['total_Op'] = pd.to_numeric(data['total_Op'])\n",
    "data['total_Opnd'] = pd.to_numeric(data['total_Opnd'])\n",
    "data['branchCount'] = pd.to_numeric(data['branchCount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf4bca8",
   "metadata": {
    "id": "8bf4bca8"
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb464aa9",
   "metadata": {
    "id": "bb464aa9"
   },
   "source": [
    "### 3. Removing rows with Not a Number values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690612b4",
   "metadata": {
    "id": "690612b4"
   },
   "outputs": [],
   "source": [
    "data = data[data['uniq_Op'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148e2d81",
   "metadata": {
    "id": "148e2d81"
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2110f057",
   "metadata": {
    "id": "2110f057"
   },
   "source": [
    "# 2. Feature Label Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d834df4",
   "metadata": {
    "id": "6d834df4"
   },
   "outputs": [],
   "source": [
    "features = ['defects']\n",
    "X = data.drop(columns=features)\n",
    "y = data.defects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14c1c59",
   "metadata": {
    "id": "f14c1c59"
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(y,label=\"Count\")       # M = 212, B = 357\n",
    "F, T = y.value_counts()\n",
    "print('Number of True: ',T)\n",
    "print('Number of False : ',F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abf4c01",
   "metadata": {
    "id": "2abf4c01"
   },
   "source": [
    "# 3. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6956f5a",
   "metadata": {
    "id": "d6956f5a"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6e11f4",
   "metadata": {
    "id": "5f6e11f4"
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(y,label=\"Count\")       # M = 212, B = 357\n",
    "T, F = y_train.value_counts()\n",
    "print('Number of True: ',T)\n",
    "print('Number of False : ',F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e52d89",
   "metadata": {
    "id": "34e52d89"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796c4068",
   "metadata": {
    "id": "796c4068"
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b1bea1",
   "metadata": {
    "id": "11b1bea1"
   },
   "source": [
    "# 4. Normalized Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242d2037",
   "metadata": {
    "id": "242d2037"
   },
   "source": [
    "## 4.1. Standard Scalar Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38106f2",
   "metadata": {
    "id": "f38106f2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_norm = sc.fit_transform(X_train)\n",
    "X_test_norm = sc.transform(X_test)\n",
    "\n",
    "X_train_norm = pd.DataFrame(X_train_norm)\n",
    "X_train_norm.columns = X_train.columns\n",
    "X_train_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2cf514",
   "metadata": {
    "id": "ff2cf514"
   },
   "source": [
    "## 4.2 Min Max Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec564ff",
   "metadata": {
    "id": "5ec564ff"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scale the goals from 0 to 1\n",
    "mms = MinMaxScaler()\n",
    "\n",
    "X_train_norm = mms.fit_transform(X_train)\n",
    "X_test_norm = mms.transform(X_test)\n",
    "\n",
    "X_train_norm = pd.DataFrame(X_train_norm)\n",
    "X_train_norm.columns = X_train.columns\n",
    "X_train_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744bd416",
   "metadata": {
    "id": "744bd416"
   },
   "source": [
    "# Convert Normalized Data into Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df9e72e",
   "metadata": {
    "id": "3df9e72e"
   },
   "outputs": [],
   "source": [
    "X_train_norm = pd.DataFrame(X_train_norm)\n",
    "X_train_norm.columns = X_train.columns\n",
    "X_train_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b4998f",
   "metadata": {
    "id": "c9b4998f"
   },
   "source": [
    "# 5. Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcfba74",
   "metadata": {
    "id": "cdcfba74"
   },
   "outputs": [],
   "source": [
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        \n",
    "        \n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2561b804",
   "metadata": {
    "id": "2561b804"
   },
   "outputs": [],
   "source": [
    "#Using Pearson Correlation\n",
    "plt.figure(figsize=(25,20))\n",
    "cor = X_train_norm.corr()\n",
    "sns.heatmap(cor, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcd9d00",
   "metadata": {
    "id": "6fcd9d00"
   },
   "outputs": [],
   "source": [
    "corr_features = correlation(X_train, 0.9)\n",
    "print(set(corr_features))\n",
    "len(set(corr_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f884815",
   "metadata": {
    "id": "1f884815"
   },
   "outputs": [],
   "source": [
    "X_drop = X_train_norm.drop(corr_features,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd0008e",
   "metadata": {
    "id": "8cd0008e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Using Pearson Correlation\n",
    "plt.figure(figsize=(15,10))\n",
    "cor = X_drop.corr()\n",
    "sns.heatmap(cor, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2031989e",
   "metadata": {
    "id": "2031989e"
   },
   "outputs": [],
   "source": [
    "X_drop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704d5462",
   "metadata": {
    "id": "704d5462"
   },
   "source": [
    "# 5. Applying chi square method for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a72a7d",
   "metadata": {
    "id": "f2a72a7d"
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "  \n",
    "# Two features with highest chi-squared statistics are selected\n",
    "chi2_features = SelectKBest(chi2, k = 5)\n",
    "X_kbest_features = chi2_features.fit_transform(X_train[X_drop.columns], y_train)\n",
    "\n",
    "# Reduced features\n",
    "print('Original feature number:', X_drop.shape[1])\n",
    "print('Reduced feature number:', X_kbest_features.shape[1])\n",
    "\n",
    "cols = chi2_features.get_support(indices=True)\n",
    "features_df_new = X_train.iloc[:,cols]\n",
    "features_df_new = features_df_new.columns\n",
    "print(features_df_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7167388e",
   "metadata": {
    "id": "7167388e"
   },
   "source": [
    "# 6. Balancing using Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ea3ac4",
   "metadata": {
    "id": "80ea3ac4"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=2)\n",
    "\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train[features_df_new], y_train.ravel())\n",
    "\n",
    "print('Random over-sampling:')\n",
    "y_train_ros = pd.DataFrame(y_train_ros)\n",
    "y_train_ros.columns = ['defects']\n",
    "\n",
    "print(y_train_ros.defects.value_counts())\n",
    "y_train_ros.defects.value_counts().plot(kind='bar', title='Count (target)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50aa779",
   "metadata": {
    "id": "a50aa779"
   },
   "outputs": [],
   "source": [
    "X_train_ros.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e58b8e4",
   "metadata": {
    "id": "5e58b8e4"
   },
   "outputs": [],
   "source": [
    "y_train_ros.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff04bec",
   "metadata": {
    "id": "4ff04bec"
   },
   "outputs": [],
   "source": [
    "X_test[features_df_new].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71678495",
   "metadata": {
    "id": "71678495"
   },
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987717aa",
   "metadata": {
    "id": "987717aa"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve,accuracy_score,classification_report,f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a46c4f6",
   "metadata": {
    "id": "9a46c4f6"
   },
   "source": [
    "# 7. Hyper Parameter Tuning & Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53c5381",
   "metadata": {
    "id": "b53c5381"
   },
   "outputs": [],
   "source": [
    "X = X_train_ros[features_df_new]\n",
    "Y = y_train_ros\n",
    "\n",
    "X_test = X_test[features_df_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3501b03",
   "metadata": {
    "id": "a3501b03"
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f6c35c",
   "metadata": {
    "id": "e0f6c35c"
   },
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debb65fe",
   "metadata": {
    "id": "debb65fe"
   },
   "source": [
    "### 1.1 Parameter Tuning for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981cfa5e",
   "metadata": {
    "id": "981cfa5e"
   },
   "outputs": [],
   "source": [
    "score_knn = cross_val_score(KNeighborsClassifier(), X, Y, cv= kf, scoring=\"accuracy\")\n",
    "print(f'Scores for each fold are: {score_knn}')\n",
    "print(f'Average score: {\"{:.2f}\".format(score_knn.mean())}')\n",
    "\n",
    "acc_max = 0\n",
    "k_max = 2\n",
    "for val in range(3,25):\n",
    "    score_knn = cross_val_score(KNeighborsClassifier(n_neighbors = val), X, Y, cv= kf, scoring=\"accuracy\")\n",
    "    curr_score = score_knn.mean()\n",
    "    curr_k = val\n",
    "    if acc_max < curr_score:\n",
    "        acc_max = curr_score\n",
    "        k_max = curr_k\n",
    "print(f'Average Max score at ({k_max}): {\"{:.3f}\".format(acc_max)}')\n",
    "\n",
    "weights = ['uniform','distance']\n",
    "acc_max = 0\n",
    "wei = 'na'\n",
    "for val in weights:\n",
    "    score_knn = cross_val_score(KNeighborsClassifier(n_neighbors = 3, weights = val), X, Y, cv= kf, scoring=\"accuracy\")\n",
    "    curr_score = score_knn.mean()\n",
    "    if acc_max < curr_score:\n",
    "        acc_max = curr_score\n",
    "        wei = val\n",
    "print(f'Average score({wei}): {\"{:.3f}\".format(score_knn.mean())}')\n",
    "\n",
    "algo = ['ball_tree','kd_tree','brute','auto']\n",
    "acc_max = 0\n",
    "algo_max = 'na'\n",
    "for val in algo:\n",
    "    score_knn = cross_val_score(KNeighborsClassifier(n_neighbors = 3, weights = 'distance' ,algorithm = val), X, Y, cv= kf, scoring=\"accuracy\")\n",
    "    curr_score = score_knn.mean()\n",
    "    if acc_max < curr_score:\n",
    "        acc_max = curr_score\n",
    "        algo_max = val\n",
    "print(f'Average score({algo_max}): {\"{:.3f}\".format(acc_max)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc6ae65",
   "metadata": {
    "id": "cdc6ae65"
   },
   "source": [
    "### 1.2 Classification Report for k Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b34ab99",
   "metadata": {
    "id": "7b34ab99"
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = k_max, weights = wei, algorithm = algo_max)\n",
    "#knn = KNeighborsClassifier()\n",
    "knn.fit(X, Y)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print(\"k Nearest Neighbor Algorithm\")\n",
    "cls_rep = classification_report(y_test, y_pred)\n",
    "print(cls_rep)\n",
    "\n",
    "#Accuracy score\n",
    "acc_knn = round(accuracy_score(y_pred,y_test),2) * 100\n",
    "f1_knn = round(f1_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "pr_knn = round(precision_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "rc_knn = round(recall_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "\n",
    "print(\"Accuracy: \",acc_knn,\"%\")\n",
    "print(\"F1 Score: \",f1_knn,\"%\")\n",
    "print(\"Precision: \",pr_knn,\"%\")\n",
    "print(\"Recall: \",rc_knn,\"%\")\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = knn.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "    \n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for KNN')\n",
    "plt.show()\n",
    "\n",
    "knn_auc = metrics.auc(fpr, tpr)\n",
    "print(\"Area Under the curve for ROC =\",knn_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab573ce",
   "metadata": {
    "id": "dab573ce"
   },
   "source": [
    "### 2.1 Parameter Tuning for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e581e401",
   "metadata": {
    "id": "e581e401"
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "score_dt = cross_val_score(tree.DecisionTreeClassifier(random_state= 42,max_depth=33), X, Y, cv= kf, scoring=\"accuracy\")\n",
    "print(f'Scores for each fold are: {score_dt}')\n",
    "print(f'Average score: {\"{:.2f}\".format(score_dt.mean())}')\n",
    "\n",
    "acc_max = 0\n",
    "max_depth = 1\n",
    "for val in range(1,50):\n",
    "    score_dt = cross_val_score(tree.DecisionTreeClassifier(max_depth= val, random_state= 42), X, Y, cv= kf, scoring=\"accuracy\")\n",
    "    curr_score = score_dt.mean()\n",
    "    curr_max_depth = val\n",
    "    if acc_max < curr_score:\n",
    "        acc_max = curr_score\n",
    "        max_depth = curr_max_depth\n",
    "print(f'Average Max score at ({max_depth}): {\"{:.3f}\".format(acc_max)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af41202c",
   "metadata": {
    "id": "af41202c"
   },
   "source": [
    "### 2.2 Classification Report for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2930c5",
   "metadata": {
    "id": "dd2930c5"
   },
   "outputs": [],
   "source": [
    "tr = tree.DecisionTreeClassifier(max_depth = max_depth, random_state = 42)\n",
    "tr.fit(X, Y) # train the ensemble classifier\n",
    "y_true, y_pred = y_test, tr.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree Algorithm\")\n",
    "tr_rep = classification_report(y_test, y_pred)\n",
    "print(tr_rep)\n",
    "\n",
    "#Accuracy score\n",
    "acc_tr = round(accuracy_score(y_pred,y_test),2) * 100\n",
    "f1_tr = round(f1_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "pr_tr = round(precision_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "rc_tr = round(recall_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "\n",
    "print(\"Accuracy: \",acc_tr,\"%\")\n",
    "print(\"F1 Score: \",f1_tr,\"%\")\n",
    "print(\"Precision: \",pr_tr,\"%\")\n",
    "print(\"Recall: \",rc_tr,\"%\")\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = tr.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "    \n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Decision Tree')\n",
    "plt.show()\n",
    "\n",
    "tr_auc = metrics.auc(fpr, tpr)\n",
    "print(\"Area Under the curve for ROC =\",tr_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d26e1f",
   "metadata": {
    "id": "76d26e1f"
   },
   "source": [
    "### 3.1 Parameter Tuning for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d0a8dc",
   "metadata": {
    "id": "a8d0a8dc"
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "acc_max = 0\n",
    "max_solver = 'na'\n",
    "algorithms = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "score_lr = cross_val_score(linear_model.LogisticRegression(random_state= 42), X, Y, cv = kf, scoring=\"accuracy\")\n",
    "print(f'Scores for each fold are:\\n {score_lr}')\n",
    "print(f'Average score: {\"{:.2f}\".format(score_lr.mean())}')\n",
    "\n",
    "for val in algorithms:\n",
    "    score_lr = cross_val_score(linear_model.LogisticRegression(solver = val, random_state= 42), X, Y, cv= kf, scoring=\"accuracy\")\n",
    "    curr_score = score_lr.mean()\n",
    "    curr_algo = val\n",
    "    if acc_max < curr_score:\n",
    "        acc_max = curr_score\n",
    "        max_solver = val\n",
    "print(f'Average Max score at ({max_solver}): {\"{:.3f}\".format(acc_max)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2b25b6",
   "metadata": {
    "id": "ac2b25b6"
   },
   "source": [
    "### 3.2 Classification Report for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a3a363",
   "metadata": {
    "id": "a5a3a363"
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver = max_solver, random_state= 42)\n",
    "lr.fit(X, Y)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Algorithm\")\n",
    "cls_rep = classification_report(y_test, y_pred)\n",
    "print(cls_rep)\n",
    "\n",
    "#Accuracy score\n",
    "acc_lr = round(accuracy_score(y_pred,y_test),2) * 100\n",
    "f1_lr = round(f1_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "pr_lr = round(precision_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "rc_lr = round(recall_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "\n",
    "print(\"Accuracy: \",acc_lr,\"%\")\n",
    "print(\"F1 Score: \",f1_lr,\"%\")\n",
    "print(\"Precision: \",pr_lr,\"%\")\n",
    "print(\"Recall: \",rc_lr,\"%\")\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = lr.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = lr.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "    \n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Logistic Regression')\n",
    "plt.show()\n",
    "\n",
    "lr_auc = metrics.auc(fpr, tpr)\n",
    "print(\"Area Under the curve for ROC =\",lr_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e426db6b",
   "metadata": {
    "id": "e426db6b"
   },
   "source": [
    "### 4. Classification Report for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b595c3eb",
   "metadata": {
    "id": "b595c3eb"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X, Y)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Algorithm\")\n",
    "rf_rep = classification_report(y_test, y_pred)\n",
    "print(rf_rep)\n",
    "\n",
    "#Accuracy score\n",
    "acc_rf = round(accuracy_score(y_pred,y_test),2) * 100\n",
    "f1_rf = round(f1_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "pr_rf = round(precision_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "rc_rf = round(recall_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "\n",
    "print(\"Accuracy: \",acc_rf,\"%\")\n",
    "print(\"F1 Score: \",f1_rf,\"%\")\n",
    "print(\"Precision: \",pr_rf,\"%\")\n",
    "print(\"Recall: \",rc_rf,\"%\")\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "    \n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Random Forest')\n",
    "plt.show()\n",
    "\n",
    "rf_auc = metrics.auc(fpr, tpr)\n",
    "print(\"Area Under the curve for ROC =\",rf_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873b4a9e",
   "metadata": {
    "id": "873b4a9e"
   },
   "source": [
    "### 5. Classification Report for Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d20f32",
   "metadata": {
    "id": "35d20f32"
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X, Y)\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "print(\"Naive Bayes Algorithm\")\n",
    "gnb_rep = classification_report(y_test, y_pred)\n",
    "print(gnb_rep)\n",
    "\n",
    "#Accuracy score\n",
    "acc_gnb = round(accuracy_score(y_pred,y_test),2) * 100\n",
    "f1_gnb = round(f1_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "pr_gnb = round(precision_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "rc_gnb = round(recall_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "\n",
    "print(\"Accuracy: \",acc_gnb,\"%\")\n",
    "print(\"F1 Score: \",f1_gnb,\"%\")\n",
    "print(\"Precision: \",pr_gnb,\"%\")\n",
    "print(\"Recall: \",rc_gnb,\"%\")\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = gnb.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Naive Bayes')\n",
    "plt.show()\n",
    "\n",
    "gnb_auc = metrics.auc(fpr, tpr)\n",
    "print(\"Area Under the curve for ROC =\",gnb_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29cbf8d",
   "metadata": {
    "id": "b29cbf8d"
   },
   "source": [
    "### 6. Classification Report for Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56699c81",
   "metadata": {
    "id": "56699c81"
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier()\n",
    "mlp.fit(X, Y)\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "#Summary of the predictions made by the classifier\n",
    "print(\"Multi Layer Perceptron Algorithm\")\n",
    "mlp_rep = classification_report(y_test, y_pred)\n",
    "print(mlp_rep)\n",
    "\n",
    "#Accuracy score\n",
    "acc_mlp = round(accuracy_score(y_pred,y_test),2) * 100\n",
    "f1_mlp = round(f1_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "pr_mlp = round(precision_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "rc_mlp = round(recall_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "\n",
    "print(\"Accuracy: \",acc_mlp,\"%\")\n",
    "print(\"F1 Score: \",f1_mlp,\"%\")\n",
    "print(\"Precision: \",pr_mlp,\"%\")\n",
    "print(\"Recall: \",rc_mlp,\"%\")\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = mlp.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1],[0, 1],'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Multi Layer Perceptron')\n",
    "plt.show()\n",
    "\n",
    "mlp_auc = metrics.auc(fpr, tpr)\n",
    "print(mlp_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5346b0c",
   "metadata": {
    "id": "c5346b0c"
   },
   "source": [
    "### 7. Classification report for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71628305",
   "metadata": {
    "id": "71628305"
   },
   "outputs": [],
   "source": [
    "svm = SVC(probability=True)\n",
    "svm.fit(X, Y)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "#Summary of the predictions made by the classifier\n",
    "print(\"Support Vector Machine Algorithm\")\n",
    "svm_rep = classification_report(y_test, y_pred)\n",
    "print(svm_rep)\n",
    "\n",
    "#Accuracy score\n",
    "acc_svm = round(accuracy_score(y_pred,y_test),2) * 100\n",
    "f1_svm = round(f1_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "pr_svm = round(precision_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "rc_svm = round(recall_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "\n",
    "print(\"Accuracy: \",acc_svm,\"%\")\n",
    "print(\"F1 Score: \",f1_svm,\"%\")\n",
    "print(\"Precision: \",pr_svm,\"%\")\n",
    "print(\"Recall: \",rc_svm,\"%\")\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = svm.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1],[0, 1],'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Support Vector Machine')\n",
    "plt.show()\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "svm_auc = metrics.auc(fpr, tpr)\n",
    "print(svm_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2570ed",
   "metadata": {
    "id": "7c2570ed"
   },
   "source": [
    "### 8. Classification Report for AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d025f16",
   "metadata": {
    "id": "9d025f16"
   },
   "outputs": [],
   "source": [
    "adb = AdaBoostClassifier(n_estimators=50, base_estimator=tr,learning_rate=1)\n",
    "# Add silent=True to avoid printing out updates with each cycle\n",
    "adb.fit(X, Y)\n",
    "y_pred = adb.predict(X_test)\n",
    "\n",
    "#Summary of the predictions made by the classifier\n",
    "print(\"Ada Boost Algorithm\")\n",
    "adb_rep = classification_report(y_test, y_pred)\n",
    "print(adb_rep)\n",
    "\n",
    "#Accuracy score\n",
    "acc_adb = round(accuracy_score(y_pred,y_test),2) * 100\n",
    "f1_adb = round(f1_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "pr_adb = round(precision_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "rc_adb = round(recall_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "\n",
    "print(\"Accuracy: \",acc_adb,\"%\")\n",
    "print(\"F1 Score: \",f1_adb,\"%\")\n",
    "print(\"Precision: \",pr_adb,\"%\")\n",
    "print(\"Recall: \",rc_adb,\"%\")\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = adb.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1],[0, 1],'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Ada Boost Algorithm')\n",
    "plt.show()\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "adb_auc = metrics.auc(fpr, tpr)\n",
    "print(adb_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a07e16",
   "metadata": {
    "id": "52a07e16"
   },
   "source": [
    "### 9. Classification Report for GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6249398",
   "metadata": {
    "id": "b6249398"
   },
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "# Add silent=True to avoid printing out updates with each cycle\n",
    "gbc.fit(X, Y)\n",
    "y_pred = gbc.predict(X_test)\n",
    "\n",
    "#Summary of the predictions made by the classifier\n",
    "print(\"Gradient Boosting Algorithm\")\n",
    "gbc_rep = classification_report(y_test, y_pred)\n",
    "print(gbc_rep)\n",
    "\n",
    "#Accuracy score\n",
    "acc_gbc = round(accuracy_score(y_pred,y_test),2) * 100\n",
    "f1_gbc = round(f1_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "pr_gbc = round(precision_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "rc_gbc = round(recall_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "\n",
    "print(\"Accuracy: \",acc_gbc,\"%\")\n",
    "print(\"F1 Score: \",f1_gbc,\"%\")\n",
    "print(\"Precision: \",pr_gbc,\"%\")\n",
    "print(\"Recall: \",rc_gbc,\"%\")\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = gbc.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1],[0, 1],'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Gradient Boosting Algorithm')\n",
    "plt.show()\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "gbc_auc = metrics.auc(fpr, tpr)\n",
    "print(gbc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f6f9fb",
   "metadata": {
    "id": "b0f6f9fb"
   },
   "source": [
    "### 10.Classification Report for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000591ac",
   "metadata": {
    "id": "000591ac",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()\n",
    "# Add silent=True to avoid printing out updates with each cycle\n",
    "xgb.fit(X, Y)\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "#Summary of the predictions made by the classifier\n",
    "print(\"XG Boost Algorithm\")\n",
    "xgb_rep = classification_report(y_test, y_pred)\n",
    "print(xgb_rep)\n",
    "\n",
    "#Accuracy score\n",
    "acc_xgb = round(accuracy_score(y_pred,y_test),2) * 100\n",
    "f1_xgb = round(f1_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "pr_xgb = round(precision_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "rc_xgb = round(recall_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "\n",
    "print(\"Accuracy: \",acc_xgb,\"%\")\n",
    "print(\"F1 Score: \",f1_xgb,\"%\")\n",
    "print(\"Precision: \",pr_xgb,\"%\")\n",
    "print(\"Recall: \",rc_xgb,\"%\")\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = xgb.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1],[0, 1],'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for XGBoost Algorithm')\n",
    "plt.show()\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "xgb_auc = metrics.auc(fpr, tpr)\n",
    "print(xgb_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae219d0",
   "metadata": {
    "id": "9ae219d0"
   },
   "source": [
    "### 11. Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af947c24",
   "metadata": {
    "id": "af947c24"
   },
   "outputs": [],
   "source": [
    "clf = VotingClassifier(estimators = [('gnb',gnb), ('lr',lr), ('tr',tr), ('svm', svm), ('mlp',mlp)], voting='soft') # construct the ensemble classifier\n",
    "clf.fit(X, Y) # train the ensemble classifier\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "\n",
    "print(\"Voting Algorithm\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#Accuracy score\n",
    "acc_clf = round(accuracy_score(y_pred,y_test),2) * 100\n",
    "f1_clf = round(f1_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "pr_clf = round(precision_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "rc_clf = round(recall_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "\n",
    "print(\"Accuracy: \",acc_clf,\"%\")\n",
    "print(\"F1 Score: \",f1_clf,\"%\")\n",
    "print(\"Precision: \",pr_clf,\"%\")\n",
    "print(\"Recall: \",rc_clf,\"%\")\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1],[0, 1],'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Voting Algorithm')\n",
    "plt.show()\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "ea_auc = metrics.auc(fpr, tpr)\n",
    "print(ea_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c89705",
   "metadata": {
    "id": "53c89705"
   },
   "source": [
    "### 12. Heterogeneous Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d6a7a0",
   "metadata": {
    "id": "20d6a7a0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf1 =  VotingClassifier(estimators = [('gnb',gnb), ('lr',lr), \n",
    "                                       ('tr',tr), ('svm', svm)], voting='soft') # construct the ensemble classifier\n",
    "\n",
    "adb1 = AdaBoostClassifier(n_estimators=5, base_estimator=clf1,learning_rate=1)\n",
    "# Add silent=True to avoid printing out updates with each cycle\n",
    "adb1.fit(X, Y)\n",
    "y_pred = adb1.predict(X_test)\n",
    "\n",
    "#Summary of the predictions made by the classifier\n",
    "print(\"Ada Boost Algorithm\")\n",
    "adb_rep1 = classification_report(y_test, y_pred)\n",
    "print(adb_rep1)\n",
    "\n",
    "#Accuracy score\n",
    "acc_adb1 = round(accuracy_score(y_pred,y_test),2) * 100\n",
    "f1_adb1 = round(f1_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "pr_adb1 = round(precision_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "rc_adb1 = round(recall_score(y_test, y_pred, average=\"macro\"),2) * 100\n",
    "\n",
    "print(\"Accuracy: \",acc_adb1,\"%\")\n",
    "print(\"F1 Score: \",f1_adb1,\"%\")\n",
    "print(\"Precision: \",pr_adb1,\"%\")\n",
    "print(\"Recall: \",rc_adb1,\"%\")\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = adb1.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1],[0, 1],'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Support Vector Machine')\n",
    "plt.show()\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "adb_auc1 = metrics.auc(fpr, tpr)\n",
    "print(adb_auc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6f87ff",
   "metadata": {
    "id": "ee6f87ff",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy\")\n",
    "print(\"1. KNN\",acc_knn)\n",
    "print(\"2. NB \",acc_gnb)\n",
    "print(\"3. LR \",acc_lr)\n",
    "print(\"4. DT \",acc_tr)\n",
    "print(\"5. SVM\",acc_svm)\n",
    "print(\"6. MLP\",acc_mlp)\n",
    "print(\"7. RF \",acc_rf)\n",
    "print(\"8. ADB Homogeneous\",acc_adb)\n",
    "print(\"9. ADB Heterogeneous\",acc_adb1)\n",
    "print(\"10. GBC\",acc_gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edb22e9",
   "metadata": {
    "id": "0edb22e9"
   },
   "outputs": [],
   "source": [
    "print(\"AUC\")\n",
    "print(\"1. KNN\",knn_auc)\n",
    "print(\"2. NB \",gnb_auc)\n",
    "print(\"3. LR \",lr_auc)\n",
    "print(\"4. DT \",tr_auc)\n",
    "print(\"5. SVM\",svm_auc)\n",
    "print(\"6. MLP\",mlp_auc)\n",
    "print(\"7. RF \",rf_auc)\n",
    "print(\"8. ADB Homogeneous\",adb_auc)\n",
    "print(\"9. ADB Heterogenous\",adb_auc1)\n",
    "print(\"10. GBC\",gbc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d45cc06",
   "metadata": {
    "id": "6d45cc06"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Project_Colab_SMOTE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
